---
title: "IDL Research Project"
author: "Lamar Foster"
date: "10/1/2021"
output: html_document
---
Audience:
-IDL people
- DSSG people
  data scientists
  students

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#clear memory
rm(list = ls())
#penalize excessive significant figures
options(digits = 3)
#preventing scientific notation
options(scipen = 10)
```
# Table of Contents

## Executive Summary

## Section 1: Data description
- What is the basic data model and how are tables related?
- What variables/fields are included in the data set and what do they measure?
High overview of what is available and how things can be merged. What variables/fields are included in the data set and what do they measure?
- How are the data organized?
- What is the size of the data?
- How many observations does it contain?
- How much storage space does it require?
- What is the file type of the raw data (.csv, .txt, etc.)?
- What is known about how the data were generated?
- Who owns the data and what kind of permissions or constraints are placed on its use?
- What is not known about the data, and how does this gap in knowledge affect the ability to work with it?
- What, if any, issues did you encounter relating to your access and/or ability to work with the data effectively?

## Section 2: Data journey
- What was done to clean or transform the data?
- What software, languages, and tools were used to work with the data?
- What questions were you trying to answer with the data?
- What analyses were conducted on the data and what were the results?

## Section 3: Data assessment
- What are the sensitivities and ethical considerations of working with this data?
- What are the strengths and limitations of working with this dataset(s)?
- What are the strengths and limitations of the methods that were applied?
- What elements in the data operationalize the key concepts and/or questions in the project?  

## Section 4: Future work
- What further questions can be asked with the data?
- What other data sets could complement or replace these data?
- What methods could be applied to answer the aforementioned questions and work with the aforementioned data sets?  
- What software, languages, and tools would be needed to answer the aforementioned questions and work with aforementioned data sets?
- What resources and/or areas of expertise would be valuable for others interested in working with the data?

## Section 5: TBD [What else would be helpful for IDL? What have we missed?]

```{r, message=FALSE}
#packages used in this analysis
if(!require(readr)){
    install.packages("readr", dependencies = TRUE)
    library(readr)
}
if(!require(ggplot2)){
    install.packages("ggplot2", dependencies = TRUE)
    library(ggplot2)
}
if(!require(dplyr)){
    install.packages("dplyr", dependencies = TRUE)
    library(dplyr)
}
if(!require(tidyr)){
    install.packages("tidyr", dependencies = TRUE)
    library(tidyr)
}
if(!require(janitor)){
    install.packages("janitor", dependencies = TRUE)
    library(janitor)
}
```
---
# Executive Summary
The Department of Housing and Urban Development (HUD) considers people spending more than 30% of their income on housing as housing burdened. Housing costs include rent, mortgage payement, property taxes, utilities, and housing insurance (Lin, 2018). There has recently been a spotlight on how energy prices, i.e. utilities, contribute to housing burden (Buylova, 2020). Energy bills of more than 6-10% of income is considered unaffordable (Hernandez & Bird, 2010; Heindl, 2015; Kontokosta et al., 2019). Previous research demonstrates energy cost burden disproportionately affect lower income households, largely because they are most at risk for living in substandard and inefficient housing (Hernandez & Phillips, 2015). Energy upgrades can  help alleviate enerrgy cost burden and potentially housing burden by saving a low-income multifamily household up to $1,500 per year per household (Kontokosta et al., 2019).

Energy cost burden is a function of both income and energy consumption. Drehobl and Ross (2016) found that an average low-income household energy burden was 7.2%, which is higher than an average higher income household energy burden of 2.3%. Findings from an evaluation of a federal energy assistance program determiined that low-income households represent 92% of all households with energy burden of 10% (APPRISE, 2005). Federal Low-Income Home Energy Assistance Program (LIHEAP) designs its funding distribution mechanism based on energy burden levels. Income is used as the main qualifier for this program.

Buyolva (2020) used two datasets: a household energy audit survey - the residential building stock assessment (RBSA) completed by the Northwest Energy Efficiency Association (NEEA) in 2017 and the American Community Survey (ACS) 2012-2017 5-year estimates data to investigate the dynamics between energy use and socio-demographic characteristics in spatial modeling of residential energy consumption.

Suggested Readings:

[Buylova, A. (2020). Spotlight on energy efficiency in Oregon: Investigating dynamics between energy use and socio-demographic characteristics in spatial modeling of residential energy consumption. Energy Policy, 140, 111439.](https://www.sciencedirect.com/science/article/pii/S0301421520301920)

[Kontokosta, C. E., Reina, V. J., & Bonczak, B. (2020). Energy cost burdens for low-income and minority households: Evidence from energy benchmarking and audit data in five US cities. Journal of the American Planning Association, 86(1), 89-105.](https://www.tandfonline.com/doi/full/10.1080/01944363.2019.1647446)
---

# Data Description

This data is from the Residential Building Stock Assessment [(RBSA)](https://neea.org/resources/rbsa-ii-combined-database) conducted in 2016-17. It has 47 comma separated variable (csv) tabular datasets that includes a representative sample of 1,130 single-family, 230 multi-family and 550 manufactured homes gathered across the Northwest region. For the single-family component, participants are recruited based on a random selection of single-family residential USPS addresses. For the multi-family component, the study recruited multi-family buildings to participate in the study and then identify tenants in those buildings willing to participate. Two auditors performed each site visit. Audits lasted approximately two hours and covered all of the major components of the homes that can be linked to the household’s overall energy use, including: building envelope, HVAC systems, lighting, appliances, electronics, and water technologies. In addition, this audit data was combined with self-reported home characteristics and demographics data that were collected in the phone survey during the recruitment of on-site sample. Supporting documentation of the RBSA data can be found [here](https://neea.org/data/residential-building-stock-assessment).

The RBSA database is comprised of a 49 files: 47 csv files, one .txt ReadMe, and an excel spreadsheet with unique database values. One of the csv tables is a data dictionary that gives a description of the column names in each csv table. The size of the csv files ranges from 2 KB to 16.6 MB. The smallest table contains 11 columns and 14 rows/observations, while the largest table contains 249 columns and 15561 rows/observations. The ReadMe details updates and changes to the RBSA II Database; changes and updates are numbered and organized by date. Each row in a table has a unique primary key (PK), making it possible to reference that specific object, and may include other relational keys (CKs) that make it possible to relate to other tables in the database. Most tables can be joined using the CK_SiteID and the CK_RoomID.

The RBSA database houses data for manufactured homes, single-family homes, multi-family residences, and multi-family buildings. Within the database, data are attributed to a Site or a Building. Building data include information collected for nonresidential portions of a multifamily building. Site data include information collected for the entirety of a single-family or manufactured home, and for residences visited at a multifamily building. The database denotes data associated with a Site by a CK_SiteID or PK_SiteID beginning with “SITE”; the database denotes data associated with a Building by a CK_SiteID or PK_SiteID beginning with “BLDG.”

```{r, message=FALSE, warning=FALSE}
#Import the RBSA data frames of interest

ols_df <- read_csv("RBSA-II-Combined-Database/One Line Summary.csv")

demog <- read_csv("RBSA-II-Combined-Database/SiteInterview_Demographics.csv")

room_df <- read_csv("RBSA-II-Combined-Database/Room.csv") #has the area of different room in each residence

site_df <- read_csv("RBSA-II-Combined-Database/SiteDetail.csv")  #redundant with ols_df

energyuse_df <- read_csv("RBSA-II-Combined-Database/SiteInterview_HomeEnergyUse.csv") #has data on energy use and energy star appliances
```

Next Steps:
- Outline Data Description following Data Brief Template = DONE
- Find parcel data for other counties in the Puget Sound Region

-Explore Data
  - Make note of tables provided and what can be merged = DONE
  - Make note of size of the data = DONE
  -Merge Data = DONE
Select Variables of Interest
 -Variables from Buylova Paper:
  Housing variables:
  1) type of housing
  2) year of construction
  3) primary heating
  4) number of bedrooms
  Household characteristics:
  1) income
  2) ownership
  3) elderly - older than 65
  4) children
  5) household size


## Data journey

###Key Steps
1) Identify data frames of interest and conduct data quality assessement
2) Merge datasets of interests
3) Subset data
4) Explore data and select variables of interest
  a) explanatory variables based on Buylova paper
5) Recode and reclassify data
6) Transform some variables
7) Create EUI variable (response variable)


The data cleaning and wrangling process followed basic data quality checks, which
included assessing the data for 1) accuracy, 2) completeness, 3) consistency, 4) timeliness,
5) validity, and 6) uniqueness (refer to Appendix for detailed information regarding this assessment).
All of the data cleaning and wrangling took place in RStudio, using base R and tidyverse programming. The first step in the cleaning process involved identifying useful datasets. The "One Line Summary" and "Site Interview Demographics" data frames were used for this analysis. The "One Line Summary" data frame exhaustive data frame that included information about energy consumption, geographic location, and building information. The "Site Interview Demographics" data frame included demographic information, such as resident's income, age, and ownership status (renter or buyer).

The next step in the data cleaning and wrangling process was identifying a primary key to merge the "One Line Summary" data frame and the "Site Interview Demographics" data frame. The data frames were merged by the "DB_SiteID" and "CK_SiteID." After the merger, the data sets were subsetted for for the "Puget Sound" region.

```{r}
#Merge ols_df to demog
  ols_demog <- left_join(ols_df, demog, by = c("DB_SiteID" = "CK_SiteID"))
```

```{r}
# Only get sites in Puget Sound Region
pug_sound_ols <- ols_demog %>%
  filter(Region == "Puget Sound")
```

```{r}
#Explore the Puget Sound Data
sum(is.na((pug_sound_ols)))

summary(pug_sound_ols)
```
Select Variables of Interest
 -Variables from Buylova Paper:
 
  Housing variables:
  1) type of housing
  2) year of construction
  3) primary heating
  4) number of bedrooms
 
  Household characteristics:
  1) income
  2) ownership
  3) elderly - older than 65
  4) children
  5) household size
```{r}
#Select variables of interest
pug_short <- pug_sound_ols %>%
  select(`Cadmus ID`, State, County,Region, `Home Type - FMP Detailed`, `Home Type - Final`, `Year Built`,`Primary Heating System`, `Qty Bedrooms`,`Reported Income`, `Do you own or rent your home`, Ownership, `Qty Occupants Between 65 Years or Older`, `Qty Occupants Between Less than 1 Year`, `Qty Occupants Between 6 and 10 Years`, `Qty Occupants.x`, `Qty Occupants.y`, `Qty Occupants Between Less than 1 Year`, `Qty Occupants Between 1 and 5 Years`, `Qty Occupants Between 6 and 10 Years`, `Qty Occupants Between 11 and 18 Years`, `Qty Occupants Between 19 and 45 Years`, `Qty Occupants Between 46 and 64 Years`, `Qty Occupants Between 65 Years or Older`, `Conditioned Area`, `Annual Electric Usage (kBtu)`)
```

```{r}
#Data Cleaning and wrangling

## Check summary of data
summary(pug_short)

## Missing values overall
sum(is.na(pug_short))

## Missing values by columns
colSums(is.na(pug_short))

# Change "prefer not say" and "Unkown" to NAs
pug_short[pug_short == "Unknown" | pug_short == "Prefer not to say"] <- NA

##Turn Certain variables into factors
pug_short_clean <- pug_short %>%
  mutate(across(c(`Home Type - FMP Detailed`, `Primary Heating System`,`Home Type - Final`,`Do you own or rent your home`:Ownership),as.factor))

# Check certain variables for missingness
sum(is.na(pug_short_clean))
sum(is.na(pug_short_clean$`Reported Income`))
sum(is.na(pug_short_clean$Ownership))
sum(is.na(pug_short_clean$`Do you own or rent your home`))
sum(is.na(pug_short_clean$`Year Built`))

#Transform a age variables to the following: 1) less than 1 to 5, 2) 6-18, 3) 19-64, 4) 65 and up
pug_short_clean_age <- pug_short_clean %>%
  rowwise() %>%
  mutate(
    age_zero_to_five = sum(`Qty Occupants Between Less than 1 Year`, `Qty Occupants Between 1 and 5 Years`),
    age_six_to_eighteen = sum(`Qty Occupants Between 6 and 10 Years`, `Qty Occupants Between 11 and 18 Years`),
    age_nineteen_to_sixtyfour = sum(`Qty Occupants Between 19 and 45 Years`, `Qty Occupants Between 46 and 64 Years`),
    age_sixtyfive_plus = `Qty Occupants Between 65 Years or Older`,
    total_occupants = `Qty Occupants.x`)

#Remove original age columns
pug_short_clean_age_short <- pug_short_clean_age %>%
  select(-c(11,13:21,))

#Make categorial variable for # of occupants
pug_short_occupant <- pug_short_clean_age_short %>%
  mutate(household_size = case_when(
    total_occupants == 1 ~ "one-person",
    total_occupants == 2 ~ "two people",
    total_occupants == 3 ~ "three people",
    total_occupants >= 4 ~ "four or more"))

#Turn occupant cat into a factor
pug_short_occupant$household_size <- factor(pug_short_occupant$household_size, levels = c("one-person", "two people", "three people", "four or more"))
levels(pug_short_occupant$household_size) # check levels for accuracy

# Make a binary children and elderly variable, elderly is anyone who is 65 and older, children is anyone 0-18 years old
pug_short_elder <- pug_short_occupant %>%
  mutate(elderly = if_else(age_sixtyfive_plus >= 1, "yes", "no")) %>%
  mutate( children = if_else(age_zero_to_five | age_six_to_eighteen >= 1, "yes", "no"))

#Set factor levels for elderly and children binary variables
pug_short_elder$elderly <- factor(pug_short_elder$elderly, levels = c("yes", "no"))
pug_short_elder$children <- factor(pug_short_elder$children, levels = c("yes", "no"))

#Change character variables to numeric
pug_short_elder$`Annual Electric Usage (kBtu)` <- as.numeric(pug_short_elder$`Annual Electric Usage (kBtu)`)
pug_short_elder$`Conditioned Area` <- as.numeric(pug_short_elder$`Conditioned Area`)

#Ceate EUI variable
pug_short_eui <- pug_short_elder %>%
  mutate(eui = `Annual Electric Usage (kBtu)`/`Conditioned Area`)

summary(pug_short_eui$eui)
summary(pug_short_eui$`Annual Electric Usage (kBtu)`)
summary(pug_short_eui$`Conditioned Area`)

#clean names
pug_eui <- clean_names(pug_short_eui)
```

```{r}
#Visualize eui
pug_eui %>%
  ggplot(aes(eui,conditioned_area)) + geom_point() + stat_smooth(method = lm) + facet_wrap(~primary_heating_system)
 
```

```{r}
#model  
lm(eui ~ conditioned_area, data = pug_eui)

lm(eui ~ home_type_final + primary_heating_system + qty_bedrooms + elderly + children + household_size + ownership, data = pug_eui) %>%
  summary()
```
# Appendices

## Apendix A: Data Quality Assessment Dimensions

1) Accuracy
  i) How well does a piece of information reflect reality?
 
2) Completenes
  i) Does it fulfill your expectations of what’s comprehensive?
 
3) Consistency
  i) Does information stored in one place match relevant data stored elsewhere?
 
4) Timeliness
  i) Is your information available when you need it?
 
5) Validity
  i) Is information in a specific format, does it follow business rules, or is it in an unusable format?
 
6) Uniqueness
  i) Is this the only instance in which this information appears in the database?
```{r}
BuildingOneLine <- read_csv("RBSA-II-Combined-Database/BuildingOneLine.csv")
View(BuildingOneLine)
```


There are 27 unique "reported income."  Future researchers may want to consider a binary variable that denotes whether a household is making a low wage based on their annual income.

They should do an imputation for the EUI, since 256 are missing (NA)
  much of the missing is coming from Apartment Buildings




Next Steps: 
Sum kBtu variables (6 total)then divide it by conditioned area to get eui
Determine EUI for apartment units using the Building One Line data frame
Continue writing report/documentation 
  













