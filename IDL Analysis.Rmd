---
title: "IDL Research Project"
author: "Lamar Foster"
date: "10/1/2021"
output: html_document
---
Audience:
-IDL people
- DSSG people
  data scientists
  students

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#clear memory
rm(list = ls())
#penalize excessive significant figures
options(digits = 3)
#preventing scientific notation
options(scipen = 10)
```
# Table of Contents

## Executive Summary

## Section 1: Data description
- What is the basic data model and how are tables related?
- What variables/fields are included in the data set and what do they measure?
High overview of what is available and how things can be merged. What variables/fields are included in the data set and what do they measure?
- How are the data organized?
- What is the size of the data?
- How many observations does it contain?
- How much storage space does it require?
- What is the file type of the raw data (.csv, .txt, etc.)?
- What is known about how the data were generated?
- Who owns the data and what kind of permissions or constraints are placed on its use?
- What is not known about the data, and how does this gap in knowledge affect the ability to work with it?
- What, if any, issues did you encounter relating to your access and/or ability to work with the data effectively?

## Section 2: Data journey
- What was done to clean or transform the data?
- What software, languages, and tools were used to work with the data?
- What questions were you trying to answer with the data?
- What analyses were conducted on the data and what were the results?

## Section 3: Data assessment
- What are the sensitivities and ethical considerations of working with this data?
- What are the strengths and limitations of working with this data set(s)?
- What are the strengths and limitations of the methods that were applied?
- What elements in the data operationalize the key concepts and/or questions in the project?  

## Section 4: Modeling
- What analyses can be done with the data 

## Section 5: Future work
- What further questions can be asked with the data?
- What other data sets could complement or replace these data?
- What methods could be applied to answer the aforementioned questions and work with the aforementioned data sets?  
- What software, languages, and tools would be needed to answer the aforementioned questions and work with aforementioned data sets?
- What resources and/or areas of expertise would be valuable for others interested in working with the data?


```{r, message=FALSE}
#packages used in this analysis
if(!require(readr)){
    install.packages("readr", dependencies = TRUE)
    library(readr)
}
if(!require(ggplot2)){
    install.packages("ggplot2", dependencies = TRUE)
    library(ggplot2)
}
if(!require(dplyr)){
    install.packages("dplyr", dependencies = TRUE)
    library(dplyr)
}
if(!require(tidyr)){
    install.packages("tidyr", dependencies = TRUE)
    library(tidyr)
}
if(!require(janitor)){
    install.packages("janitor", dependencies = TRUE)
    library(janitor)
}
if(!require(stringr)){
    install.packages("stringr", dependencies = TRUE)
    library(stringr)
}
library(DataExplorer)
```
---
# Executive Summary
The purpose of this documentation is to outline the preprocessing of the residential building stock assessment (RBSA) dataset to determine its research potential. Results from the exploratory data analysis suggest that the RBSA data is a valuable dataset for identifying energy consumption and equity issues. The RBSA allows researchers to identify energy efficiency opportunities, the efficiency of specific appliances, and much more. The RBSA dataset includes residential demographic data, allowing researchers to disaggregate energy efficiency by family size, income, education level, age, and other demographic constructs. However, the RBSA demographic data frame does not provide race/ethnicity nor gender data. More research opportunities become available when the RBSA data is merged with other data. For example, Buylova (2020) was able to identify which regions in Oregon and racial/ethnic groups were more susceptible to high energy burden by combining the RBSA data with the American Community Survey (ACS) data.

This document loosely follows the methods Buylova employed to conduct her analysis. Buylova's analysis included housing variables and household characteristic variables. My data exploration includes cleaning and wrangling the RBSA data to create the same variables Buylova used and more. As aforementioned, Buylova (2020) used the RBSA data completed by the Northwest Energy Efficiency Association (NEEA) in 2017 and the 2012-2017 ACS data to investigate the dynamics between energy use and socio-demographic characteristics in spatial modeling of residential energy consumption. The underlying research inquiry guiding this exploratory data analysis of the RBSA data is the confluence of energy cost and housing burden.

The Department of Housing and Urban Development (HUD) considers people spending more than 30% of their income on housing as housing burdened. Housing costs include rent, mortgage payment, property taxes, utilities, and housing insurance (Lin, 2018). There has recently been a focus on how energy prices, i.e., utilities, contribute to housing burden. Energy bills of more than 6-10% of income are considered unaffordable (Hernandez & Bird, 2010; Heindl, 2015; Kontokosta et al., 2019). Previous research demonstrates that the energy cost burden disproportionately affects lower-income households because they are most at risk for living in substandard and inefficient housing (Hernandez & Phillips, 2015). Energy upgrades can help alleviate energy cost burden and potentially housing burden by saving a low-income multifamily household up to $1,500 per year per household (Kontokosta et al., 2019).

Energy cost burden is a function of both income and energy consumption. Drehobl and Ross (2016) found that an average low-income household energy burden was 7.2%, higher than an average higher-income household energy burden of 2.3%. Findings from a federal energy assistance program evaluation determined that low-income households represent 92% of all households with an energy burden of 10% (APPRISE, 2005). The Federal Low-Income Home Energy Assistance Program designs its funding distribution mechanism based on energy burden levels. Income is used as the primary qualifier for this program.

This document is organized into five sections to illustrate the potential of the RBSA data. Section 1 describes the data; section 2 outlines the data cleaning and wrangling process; section 3 examines ethical considerations for using the data; section 4 suggests inferential and machine learning models that can be done with the data. Finally, section 5 concludes by providing uses of the RBSA data when merged with other data.

Suggested Readings:

[Buylova, A. (2020). Spotlight on energy efficiency in Oregon: Investigating dynamics between energy use and socio-demographic characteristics in spatial modeling of residential energy consumption. Energy Policy, 140, 111439.](https://www.sciencedirect.com/science/article/pii/S0301421520301920)

[Kontokosta, C. E., Reina, V. J., & Bonczak, B. (2020). Energy cost burdens for low-income and minority households: Evidence from energy benchmarking and audit data in five US cities. Journal of the American Planning Association, 86(1), 89-105.](https://www.tandfonline.com/doi/full/10.1080/01944363.2019.1647446)
---

## Section 1: Data description

### Key Steps
1) Explored and discovered existing data documentation 
2) Identified data frames of interest 
3) Discerned relationship between data frames 

This data is from the Residential Building Stock Assessment [(RBSA)](https://neea.org/resources/rbsa-ii-combined-database) conducted in 2016-17. It has 47 comma separated variable (csv) tabular data sets that includes a representative sample of 1,130 single-family, 230 multi-family and 550 manufactured homes gathered across the Northwest region. For the single-family component, participants are recruited based on a random selection of single-family residential USPS addresses. For the multi-family component, the study recruited multi-family buildings to participate in the study and then identify tenants in those buildings willing to participate. Two auditors performed each site visit. Audits lasted approximately two hours and covered all of the major components of the homes that can be linked to the household’s overall energy use, including: building envelope, HVAC systems, lighting, appliances, electronics, and water technologies. In addition, this audit data was combined with self-reported home characteristics and demographics data that were collected in the phone survey during the recruitment of on-site sample. Supporting documentation of the RBSA data can be found [here](https://neea.org/data/residential-building-stock-assessment).

The RBSA database is comprised of a 49 files: 47 csv files, one .txt ReadMe, and an excel spreadsheet with unique database values. One of the csv tables is a data dictionary that gives a description of the column names in each csv table. The size of the csv files ranges from 2 KB to 16.6 MB. The smallest table contains 11 columns and 14 rows/observations, while the largest table contains 249 columns and 15561 rows/observations. The ReadMe details updates and changes to the RBSA II Database; changes and updates are numbered and organized by date. Each row in a table has a unique primary key (PK), making it possible to reference that specific object, and may include other relational keys (CKs) that make it possible to relate to other tables in the database. Most tables can be joined using the CK_SiteID and the CK_RoomID.

The RBSA database houses data for manufactured homes, single-family homes, multi-family residences, and multi-family buildings. Within the database, data are attributed to a Site or a Building. Building data include information collected for nonresidential portions of a multifamily building. Site data include information collected for the entirety of a single-family or manufactured home, and for residences visited at a multifamily building. The database denotes data associated with a Site by a CK_SiteID or PK_SiteID beginning with “SITE”; the database denotes data associated with a Building by a CK_SiteID or PK_SiteID beginning with “BLDG.”

```{r, message=FALSE, warning=FALSE}
#Import the RBSA data frames of interest

ols_df <- read_csv("RBSA-II-Combined-Database/One Line Summary.csv")

demog <- read_csv("RBSA-II-Combined-Database/SiteInterview_Demographics.csv")

room_df <- read_csv("RBSA-II-Combined-Database/Room.csv") #has the area of different room in each residence

site_df <- read_csv("RBSA-II-Combined-Database/SiteDetail.csv")  #redundant with ols_df

energyuse_df <- read_csv("RBSA-II-Combined-Database/SiteInterview_HomeEnergyUse.csv") #has data on energy use and energy star appliances
```


```{r}
introduce(ols_df)
```

---

## Section 2: Data journey

###Key Steps
1) Identified and merged data frames of interest
3) Subset the data for region of interest
4) Explored data and selected variables of interest
  a) explanatory variables based on Buylova paper
5) Recoded and reclassified data
6) Transformed variables of interest
7) Created EUI variable (response variable)


The data cleaning and wrangling process followed basic data quality checks, which included assessing the data for 1) accuracy, 2) completeness, 3) consistency, 4) timeliness, 5) validity, and 6) uniqueness (refer to Appendix A for detailed information regarding this assessment). All of the data cleaning and wrangling took place in R Studio, using base R and tidyverse syntax. The first step in the cleaning process involved identifying useful data sets. The "One Line Summary" and "Site Interview Demographics" data frames were used to create the analytic data set. The data cleaning and wrangling was driven by trying to replicate the analysis done in the [Buylova (2020)](https://www.sciencedirect.com/science/article/pii/S0301421520301920) paper. Dplyr from the tidyverse was used to merge the "One Line Summary" to the "Site Interview Demographics" data frames.The "One Line Summary" data frame has data concerning energy consumption, geographic location, and building information. The primary key for the merger were the "DB_SiteID" and "CK_SiteID." The "Site Interview Demographics" data frame included demographic information, such as resident's income, age, and ownership status (renter or buyer). 

After the merger, the data frame was subsetted for for the "Puget Sound" region. Next, housing variables and household characteristic variables, as outlined by the Buylova (2020) paper, were selected for the analytical data frame (refer to Appendix B to learn more about the housing and household characteristic variables). The EUI, the response variable, was created by dividing the total energy consumption in British Thermal Units (kBTU) by the conditioned living area of the home (sq. foot). To do this, variables with kBTU units were identified and used in the analytic data set. Once the analytic data frame had all the necessary variables, it was checked for missingness. 

The first attempt of checking for missing data resulted in there being zero missing data. Upon further examination, it was revealed that missing data in the RBSA data set were coded as "unknown" or "prefer not to say." Variables with those observations were recoded as NA (missing). To replicate the Buylova (2020) model, many variables needed to be transformed, such as age variables, income variables, and the total occupants variable. Finally, the "janitor" package was used to make all of the variables lowercase and if applicable snake case. 

```{r}
#Merge ols_df to demog
  ols_demog <- left_join(ols_df, demog, by = c("DB_SiteID" = "CK_SiteID"))
```

```{r}
# Only get sites in Puget Sound Region
pug_sound_ols <- ols_demog %>%
  filter(Region == "Puget Sound")
```

```{r}
#Explore the Puget Sound Data
sum(is.na((pug_sound_ols)))
```

```{r}
#Select variables of interest
pug_short <- pug_sound_ols %>%
  select(`Cadmus ID`, State, County,Region, `Home Type - FMP Detailed`, `Home Type - Final`, `Year Built`,`Primary Heating System`, `Qty Bedrooms`,`Reported Income`, `Do you own or rent your home`, Ownership, `Qty Occupants Between 65 Years or Older`, `Qty Occupants Between Less than 1 Year`, `Qty Occupants Between 6 and 10 Years`, `Qty Occupants.x`, `Qty Occupants.y`, `Qty Occupants Between Less than 1 Year`, `Qty Occupants Between 1 and 5 Years`, `Qty Occupants Between 6 and 10 Years`, `Qty Occupants Between 11 and 18 Years`, `Qty Occupants Between 19 and 45 Years`, `Qty Occupants Between 46 and 64 Years`, `Qty Occupants Between 65 Years or Older`, `Conditioned Area`, contains("kBtu"))
```

```{r}
#Data Cleaning and wrangling

## Check summary of data
summary(pug_short)

## Missing values overall
sum(is.na(pug_short))

## Missing values by columns
colSums(is.na(pug_short))

# Change "prefer not say" and "Unkown" to NAs
pug_short[pug_short == "Unknown" | pug_short == "Prefer not to say" | pug_short == "N/A"] <- NA

##Turn Certain variables into factors
pug_short_clean <- pug_short %>%
  mutate(across(c(`Home Type - FMP Detailed`, `Primary Heating System`,`Home Type - Final`,`Do you own or rent your home`:Ownership),as.factor))

# Check certain variables for missingness
sum(is.na(pug_short_clean))
sum(is.na(pug_short_clean$`Reported Income`))
sum(is.na(pug_short_clean$Ownership))
sum(is.na(pug_short_clean$`Do you own or rent your home`))
sum(is.na(pug_short_clean$`Year Built`))

#Transform a age variables to the following: 1) less than 1 to 5, 2) 6-18, 3) 19-64, 4) 65 and up
pug_short_clean_age <- pug_short_clean %>%
  rowwise() %>%
  mutate(
    age_zero_to_five = sum(`Qty Occupants Between Less than 1 Year`, `Qty Occupants Between 1 and 5 Years`),
    age_six_to_eighteen = sum(`Qty Occupants Between 6 and 10 Years`, `Qty Occupants Between 11 and 18 Years`),
    age_nineteen_to_sixtyfour = sum(`Qty Occupants Between 19 and 45 Years`, `Qty Occupants Between 46 and 64 Years`),
    age_sixtyfive_plus = `Qty Occupants Between 65 Years or Older`,
    total_occupants = `Qty Occupants.x`)

#Remove original age columns
pug_short_clean_age_short <- pug_short_clean_age %>%
  select(-c(11,13:21,))

#Make categorial variable for # of occupants
pug_short_occupant <- pug_short_clean_age_short %>%
  mutate(household_size = case_when(
    total_occupants == 1 ~ "one-person",
    total_occupants == 2 ~ "two people",
    total_occupants == 3 ~ "three people",
    total_occupants >= 4 ~ "four or more"))

#Turn occupant cat into a factor
pug_short_occupant$household_size <- factor(pug_short_occupant$household_size, levels = c("one-person", "two people", "three people", "four or more"))
levels(pug_short_occupant$household_size) # check levels for accuracy

# Make a binary children and elderly variable, elderly is anyone who is 65 and older, children is anyone 0-18 years old
pug_short_elder <- pug_short_occupant %>%
  mutate(elderly = if_else(age_sixtyfive_plus >= 1, "yes", "no")) %>%
  mutate( children = if_else(age_zero_to_five | age_six_to_eighteen >= 1, "yes", "no"))

#Set factor levels for elderly and children binary variables
pug_short_elder$elderly <- factor(pug_short_elder$elderly, levels = c("yes", "no"))
pug_short_elder$children <- factor(pug_short_elder$children, levels = c("yes", "no"))

#Change character variables to numeric
pug_short_elder$`Annual Electric Usage (kBtu)` <- as.numeric(pug_short_elder$`Annual Electric Usage (kBtu)`)
pug_short_elder$`Annual Gas Usage (kBtu)` <- as.numeric(pug_short_elder$`Annual Gas Usage (kBtu)`)
pug_short_elder$`Conditioned Area` <- as.numeric(pug_short_elder$`Conditioned Area`)

#Ceate EUI variable
#pug_short_eui <- 
pug_short_eui <- pug_short_elder %>%
  rowwise() %>% 
  mutate(annual_energy_use = sum(c_across(contains("kBtu")), na.rm = TRUE)) %>% 
  mutate(annual_energy_use = na_if(annual_energy_use, 0)) %>% 
  mutate(eui = annual_energy_use/`Conditioned Area`)

#Tranform the income variable 
pug_eui_income <- pug_short_eui %>% 
  mutate(Reported_Income = str_replace(`Reported Income`, "\\s", "_")) %>% 
  separate(Reported_Income, into = c("lower_income", "higher_income"), sep = "_") %>% 
  mutate(lower_income = parse_number(lower_income),
         higher_income = parse_number(higher_income)) %>%
  mutate(lower_income = if_else(is.na(lower_income), higher_income, lower_income),
         higher_income = if_else(is.na(higher_income), lower_income, higher_income)) %>% 
  mutate(Average_Reported_Income = (lower_income+higher_income)/2) %>% 
  clean_names()

# Create Socioeconomic Status (SES) Variable based on average income and household size 
# the low-wage income was based on the Washington State Low-Income Weatherization Program, https://www.commerce.wa.gov/wp-content/uploads/2021/02/2021-WA-Low-Income-Eligiblity-Guidelines.pdf 

# Middle class numbers were derived from DSHS State Median Income Charts. Multiplying monthly income by 11 (months).  https://www.dshs.wa.gov/esa/eligibility-z-manual-ea-z/state-median-income-chart 

#Note that these numbers are for 2021 and the data is from 2016. More research should be done to better reflect SES in the data

pug_eui <- pug_eui_income %>% 
  mutate(ses = case_when(
    average_reported_income < 31752 ~ "low",
    average_reported_income <= 41521 & total_occupants == 2 ~ "low",
    average_reported_income <= 51291 & total_occupants == 3 ~ "low",
    average_reported_income <= 61061 & total_occupants >= 4 ~ "low",
    average_reported_income = 4454*11 & average_reported_income < 5825*11 & (total_occupants == 1) ~ "middle",
    average_reported_income = 5825*11 & average_reported_income < 7195*11 & (total_occupants >= 2) ~ "middle",
    average_reported_income = 7195*11 & average_reported_income < 8566*11 & (total_occupants >= 3) ~ "middle",
    average_reported_income = 8566*11 & average_reported_income < 9936*11 & (total_occupants >= 4) ~ "middle",
    TRUE ~ "high")
    ) %>%
  mutate(ses = ifelse(is.na(average_reported_income), NA, ses)) %>% 
  mutate(ses = factor(ses, levels = c("low", "middle", "high")))
```

---
## Section 3: Data assessment

###Key Steps
1) Reading literature of data ethics 
2) Exploring data for identifiability 
3) Identifying potential data mergers that may raise privacy concerns

- What are the sensitivities and ethical considerations of working with this data?
- What are the strengths and limitations of working with this data set(s)?
- What are the strengths and limitations of the methods that were applied?
- What elements in the data operationalize the key concepts and/or questions in the project?  

Identifiability is becoming less of a binary and more of a continuum. In other words, privacy is not about private or public, but about how much information is disclosed, which in turn can make certain groups and individuals more seen. The RBSA is publicly available data that does not disclose individual addresses or people's names. However, a person's zip code, type of house, annual income, and the age of the homeowners/residents can result in indiviudal houses becoming more identifiable. Disclosure risks increase with dimensionality (more variables), linking multiple data sources, and using data analytics. This may run the risk of not adequatley protecting vulnerbale groups in the data set. For example, if this data is merged with other data sets, someone can identify households that are comprised of only elederly people or single people. This is a cause for concern for these vulnerable groups. Geospatial analyses need to be done with care to mitigate the potential for identifying people.

Suggested Readings:

[Corti, L. & Bishop, L (year).Legal and ethical challenges surrounding big data: energy data](https://dam.ukdataservice.ac.uk/media/604999/ukds-case-studies-ethical.pdf)

[McKenna, E., Richardson, I., & Thomson, M. (2012). Smart meter data: Balancing consumer privacy concerns with legitimate applications. Energy Policy, 41, 807-814.](https://www.sciencedirect.com/science/article/abs/pii/S0301421511009438?casa_token=l789RhCZXBoAAAAA:1roGNDysGtPGYRRLFUt_3h1iWGH0Lz90OcN4Q5QxqVmKvnOMSWJZx5o0agOjt0e-sqexzbmvkw)
```{r}
#Visualize eui
pug_eui %>%
  ggplot(aes(eui,conditioned_area)) + geom_point() + stat_smooth(method = lm) + facet_wrap(~primary_heating_system)
 
```

---

## Section 4: Modeling
- What analyses can be done with the data 
- What models were built 

```{r}
#model  
lm(eui ~ conditioned_area, data = pug_eui)

lm(eui ~ home_type_final + primary_heating_system + qty_bedrooms + elderly + children + household_size + ownership, data = pug_eui) %>%
  summary()
```

---

## Section 5: Future work
- What further questions can be asked with the data?
- What other data sets could complement or replace these data?
- What methods could be applied to answer the aforementioned questions and work with the aforementioned data sets?  
- What software, languages, and tools would be needed to answer the aforementioned questions and work with aforementioned data sets?
- What resources and/or areas of expertise would be valuable for others interested in working with the data?

# Appendices

## Appendix A: Data Quality Assessment Dimensions

1) Accuracy
  i) How well does a piece of information reflect reality?
 
2) Completeness
  i) Does it fulfill your expectations of what’s comprehensive?
 
3) Consistency
  i) Does information stored in one place match relevant data stored elsewhere?
 
4) Timeliness
  i) Is your information available when you need it?
 
5) Validity
  i) Is information in a specific format, does it follow business rules, or is it in an unusable format?
 
6) Uniqueness
  i) Is this the only instance in which this information appears in the database?
  
## Appendix B: Buylova (2020) variables of interest
  I. Housing variables:
  1) type of housing
  2) year of construction
  3) primary heating
  4) number of bedrooms
 
  II. Household characteristics:
  1) income
  2) ownership
  3) elderly - older than 65
  4) children
  5) household size
```{r}
BuildingOneLine <- read_csv("RBSA-II-Combined-Database/BuildingOneLine.csv")
View(BuildingOneLine)
```


There are 27 unique "reported income."  Future researchers may want to consider a binary variable that denotes whether a household is making a low wage based on their annual income.

They should do an imputation for the EUI, since 256 are missing (NA)
  much of the missing is coming from Apartment Buildings




Next Steps: 
Sum kBtu variables (6 total)then divide it by conditioned area to get eui
Determine EUI for apartment units using the Building One Line data frame
Continue writing report/documentation 
  













